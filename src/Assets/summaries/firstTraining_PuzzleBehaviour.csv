Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
1000,2.484209,18.75925925925926,-0.7630847,66.78,66.78,1.0
2000,2.4842756,19.0,-0.5643364,6.02,6.02,1.0
3000,2.4839888,18.96153846153846,-0.22472568,26.72,26.72,1.0
4000,2.4839013,18.489795918367346,0.046144497,124.47058823529412,124.47058823529412,1.0
5000,2.4837348,18.89830508474576,0.29456672,45.372549019607845,45.372549019607845,1.0
6000,2.4818738,18.636363636363637,0.7561368,64.72549019607843,64.72549019607843,1.0
7000,2.4799752,18.755102040816325,1.1495578,46.52,46.52,1.0
8000,2.477377,18.764705882352942,1.4543064,46.31372549019608,46.31372549019608,1.0
9000,2.4734836,18.529411764705884,1.7967647,85.03921568627452,85.03921568627452,1.0
10000,2.4706528,18.50980392156863,2.0699723,65.33333333333333,65.33333333333333,1.0
11000,2.464115,18.568627450980394,2.5693433,104.74509803921569,104.74509803921569,1.0
12000,2.4580355,18.647058823529413,2.896598,104.82352941176471,104.82352941176471,1.0
13000,2.4543595,18.607142857142858,3.2988348,85.43137254901961,85.43137254901961,1.0
14000,2.4538555,18.804347826086957,3.820962,66.2156862745098,66.2156862745098,1.0
15000,2.450216,19.0,3.9760735,6.64,6.64,1.0
16000,2.4477897,18.803030303030305,4.2103963,87.08,87.08,1.0
17000,2.4412587,18.08108108108108,4.7093434,142.03846153846155,142.03846153846155,1.0
